{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "Neural network comprise of layers / modules that perform operations on data. \n",
    "\n",
    "The torch.nn namespsaces provides all the building blocks you need to build your own neurual network. Every module in pytorch subclasses the nn.module. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex archetectures easily.\n",
    "\n",
    "The following sections, we'll build a nn to classify the fashionmnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get device for training\n",
    "\n",
    "We want to be able to train our model on a hardware accelerator like gpu or mps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"using {device} device\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Class\n",
    "\n",
    "We define our nerual network by subclassing nn.module, and initialize the nerual network layers in init. Every nn.module subclass implements the operations on input data in the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of neurualnetwork , and move it to the device, and print its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model, we pass it the input data. This executes the models forward, along with some background options. Do not call model.forward directly\n",
    "\n",
    "Calling the the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the indiviual values of each output. \n",
    "\n",
    "We get the prediction probabilities by passing it through an instance of the nn.softmax module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers\n",
    "\n",
    "lets break down the layers in the fashionmnist model. \n",
    "\n",
    "To illustrate it, we will take a sample minibatch of 3 images of size 28x28 and see what happens to it as we pass it though the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.flatten\n",
    "\n",
    "We initialize the nn.flatten layer to convert each 2d 28x28 image into a contiguous array of 784 pixel values ( the minibatch dimension is maintained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.linear\n",
    "\n",
    "the linear layer is a modeule that applies a linear tranformation on the input using its stored weights and bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "\n",
    "print(hidden1.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.relu\n",
    "\n",
    "Non-linear activations are what create the complex mapping between the models inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena\n",
    "\n",
    "This model, we use nn.relu betwen our linear layes, but there other activation functions to introduce non-linearity in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before relu: tensor([[ 0.3142, -0.1475,  0.7625, -0.1126, -0.0028,  0.4756, -0.2604, -0.1498,\n",
      "         -0.1373,  0.0050,  0.1223,  0.3017, -0.0232, -0.6451, -0.1084,  0.2931,\n",
      "          0.2026, -0.3242, -0.0237, -0.1021],\n",
      "        [ 0.1892,  0.0031,  0.4144, -0.2846, -0.1556, -0.1566, -0.0593,  0.0804,\n",
      "          0.0124, -0.1292,  0.0777,  0.4637, -0.4387, -0.8024, -0.0849,  0.4886,\n",
      "          0.1013, -0.1476, -0.1980, -0.1790],\n",
      "        [ 0.0638,  0.3232,  0.7931, -0.0231, -0.0059,  0.4532, -0.3270, -0.0854,\n",
      "          0.1416,  0.2374, -0.1072,  0.4645, -0.1028, -0.7788,  0.0210,  0.3702,\n",
      "          0.2642, -0.0280, -0.0492,  0.1410]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      "\n",
      "after relu: tensor([[0.3142, 0.0000, 0.7625, 0.0000, 0.0000, 0.4756, 0.0000, 0.0000, 0.0000,\n",
      "         0.0050, 0.1223, 0.3017, 0.0000, 0.0000, 0.0000, 0.2931, 0.2026, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1892, 0.0031, 0.4144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0804, 0.0124,\n",
      "         0.0000, 0.0777, 0.4637, 0.0000, 0.0000, 0.0000, 0.4886, 0.1013, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0638, 0.3232, 0.7931, 0.0000, 0.0000, 0.4532, 0.0000, 0.0000, 0.1416,\n",
      "         0.2374, 0.0000, 0.4645, 0.0000, 0.0000, 0.0210, 0.3702, 0.2642, 0.0000,\n",
      "         0.0000, 0.1410]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"before relu: {hidden1} \\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"after relu: {hidden1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
