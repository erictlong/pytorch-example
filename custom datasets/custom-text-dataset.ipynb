{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use dataset and custom dataloaders\n",
    "\n",
    "Quick turiorial on how to use dataloaders with pytorch\n",
    "\n",
    "orginal code: https://towardsdatascience.com/how-to-use-datasets-and-dataloader-in-pytorch-for-custom-text-data-270eed7f7c00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pytorch dataset and managing it with dataloader keeps the data manageable.\n",
    "\n",
    "Defines:\n",
    "- Dataset stores all your data\n",
    "- Dataloader is can be used to iterate though the data, manage batches, transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        \"\"\"\n",
    "        When initialize the class you need to inmport two variables\n",
    "        Variables:\n",
    "        - text\n",
    "        - labels\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        returns the length of the labels when called\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        function is used by pytorch dataset module to get a \n",
    "        sample and construct the dataset\n",
    "\n",
    "        idx passed in to the function is a number, this number is the data instance which\n",
    "        dataset will be looping through\n",
    "\n",
    "        sample containing a dictionary storing the data. This stores in \n",
    "        another dictonary consisting of all the data in the dataset\n",
    "        \"\"\"\n",
    "        label = self.labels[idx]\n",
    "        text = self.text[idx]\n",
    "        sample = {\"Text\": text, \"Class\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Custom textDataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example pandas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
    "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
    "\n",
    "text_labels_df = pd.DataFrame({'Text': text, 'Labels': labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define data set object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = CustomTextDataset(text_labels_df['Text'], text_labels_df['Labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset is initialised and ready to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Example\n",
    "\n",
    "Show how the data is stored within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First iteration of data set:  {'Text': 'Happy', 'Class': 'Positive'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nFirst iteration of data set: ', next(iter(TD)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data set:  5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Length of data set: ', len(TD), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire data set:  [{'Text': ['Happy'], 'Class': ['Positive']}, {'Text': ['Amazing'], 'Class': ['Positive']}, {'Text': ['Sad'], 'Class': ['Negative']}, {'Text': ['Unhapy'], 'Class': ['Negative']}, {'Text': ['Glum'], 'Class': ['Negative']}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Entire data set: ', list(DataLoader(TD)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to prepoecess data using collate fn\n",
    "\n",
    "In ML and DL text needs to be cleaned and turned in to vectors prior to training. \n",
    "Dataloader has a handy parameter called collate_fn. this parameter allows you to create separate data processing functions and will apply the processing within that function to the data before it is output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    word_tensor = torch.tensor([[1.], [0.], [45.]])\n",
    "    label_tensor = torch.tensor([[1.]])\n",
    "\n",
    "    text_list, classes = [], []\n",
    "\n",
    "    for (_text, _class) in batch:\n",
    "        text_list.append(word_tensor)\n",
    "        classes.append(label_tensor)\n",
    "    \n",
    "    text = torch.cat(text_list)\n",
    "    classes = torch.tensor(classes)\n",
    "\n",
    "    return text, classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an example, two tensors are created to represent the word and class.\n",
    "\n",
    "In practice, these could be word vectors passed in through another function. \n",
    "The batch is the unpacked and then we add the word and label tensors to lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word tensors are then concatenated and the list of class tensors, in this case 1, are combined into a single tensor. Funciton will now return processed text data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL_DS = DataLoader(TD, batch_size=2, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to iterate through the dataset when training a model\n",
    "\n",
    "We will iterate though the Dataset without using collate fn because its easier to see how the words and classes are being ouptut by dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 text data: ['Sad', 'Unhapy']\n",
      "0 Class data:  ['Negative', 'Negative'] \n",
      "\n",
      "1 text data: ['Amazing', 'Happy']\n",
      "1 Class data:  ['Positive', 'Positive'] \n",
      "\n",
      "2 text data: ['Glum']\n",
      "2 Class data:  ['Negative'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DL_DS = DataLoader(TD, batch_size=2, shuffle=True)\n",
    "\n",
    "for (idx, batch) in enumerate(DL_DS):\n",
    "    # print the text data of the batch\n",
    "    print(idx, 'text data:', batch['Text'])\n",
    "\n",
    "    # print the class data of batch\n",
    "    print(idx, 'Class data: ', batch['Class'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([[ 1.],\n",
      "        [ 0.],\n",
      "        [45.],\n",
      "        [ 1.],\n",
      "        [ 0.],\n",
      "        [45.]]), tensor([1., 1.]))\n",
      "1 (tensor([[ 1.],\n",
      "        [ 0.],\n",
      "        [45.],\n",
      "        [ 1.],\n",
      "        [ 0.],\n",
      "        [45.]]), tensor([1., 1.]))\n",
      "2 (tensor([[ 1.],\n",
      "        [ 0.],\n",
      "        [45.]]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "DL_DS_CL = DataLoader(TD, batch_size=2, collate_fn=collate_batch, shuffle=True)\n",
    "\n",
    "for (idx, batch) in enumerate(DL_DS_CL):\n",
    "    print(idx, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data does not appear correct. additional work is needed to review\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
